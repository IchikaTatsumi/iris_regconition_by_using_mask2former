import cv2
import torch
import numpy as np
import json
import time
import albumentations as A
from albumentations.pytorch import ToTensorV2
import sys
import os
import torch.nn.functional as F

# --- SETUP ƒê∆Ø·ªúNG D·∫™N ---
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from src.models.mask2former import EnhancedMask2Former
except ImportError:
    print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y module 'src'.")
    sys.exit(1)

class IrisSegmentor:
    def __init__(self, config_path, checkpoint_path):
        # Thi·∫øt b·ªã
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'
        print(f"üöÄ Phan cung: {device_name}")

        # 1. Load Config
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        # X·ª≠ l√Ω config
        model_cfg = self.config.get('model', self.config.get('model_config', {}))
        for k in ['architecture', 'model_type', 'use_checkpoint']:
            if k in model_cfg: del model_cfg[k]

        # 2. Init Model
        print("üèóÔ∏è Dang khoi tao Model...")
        try:
            self.model = EnhancedMask2Former(**model_cfg)
        except TypeError:
            model_cfg = {k:v for k,v in model_cfg.items() if k in ['num_labels', 'model_name', 'num_queries']}
            self.model = EnhancedMask2Former(**model_cfg)

        # 3. Load Weights
        print(f"‚öñÔ∏è Dang tai trong so (Weights)...")
        if not os.path.exists(checkpoint_path):
            print(f"‚ùå File khong ton tai: {checkpoint_path}")
            sys.exit(1)

        try:
            ckpt = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            state_dict = ckpt.get('model_state_dict', ckpt.get('state_dict', ckpt.get('model', ckpt)))
            self.model.load_state_dict(state_dict)
            print("‚úÖ Da tai Model thanh cong!")
        except Exception as e:
            print(f"‚ùå Loi load weights: {e}")
            sys.exit(1)

        self.model.to(self.device).eval()

        # 4. Transform - QUAN TR·ªåNG: 320x320 ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô
        self.img_size = 320
        self.transform = A.Compose([
            A.Resize(self.img_size, self.img_size),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ])

    def predict_raw_probs(self, frame):
        """
        Tr·∫£ v·ªÅ b·∫£n ƒë·ªì x√°c su·∫•t k√≠ch th∆∞·ªõc nh·ªè (320x320) ƒë·ªÉ x·ª≠ l√Ω cho nhanh
        """
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        x = self.transform(image=img_rgb)['image'].unsqueeze(0).to(self.device)

        with torch.no_grad():
            with torch.amp.autocast('cuda'):
                out = self.model(x)
                logits = out.get('pred_masks', out.get('logits', out))
                
                # Softmax -> X√°c su·∫•t
                probs = F.softmax(logits, dim=1)
                
                # L·∫•y k√™nh Iris (Class 1)
                iris_prob = probs[0, 1, :, :] # [320, 320]
                
        # Tr·∫£ v·ªÅ numpy array k√≠ch th∆∞·ªõc 320x320 (Ch∆∞a resize v·ªôi)
        return iris_prob.cpu().float().numpy()

def nothing(x):
    pass

def main():
    CONFIG = 'configs/mask2former_config_kaggle.json'
    CKPT = 'checkpoints/best_checkpoint.pth'

    segmentor = IrisSegmentor(CONFIG, CKPT)
    
    cap = cv2.VideoCapture(0)
    # Thi·∫øt l·∫≠p ƒë·ªô ph√¢n gi·∫£i Webcam
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # --- T·∫†O C·ª¨A S·ªî ƒêI·ªÄU KHI·ªÇN TI·∫æNG VI·ªÜT ---
    # L∆∞u √Ω: OpenCV ƒë√¥i khi hi·ªÉn th·ªã ti·∫øng Vi·ªát c√≥ d·∫•u b·ªã l·ªói font tr√™n Windows Title
    # n√™n m√¨nh d√πng Ti·∫øng Vi·ªát kh√¥ng d·∫•u ho·∫∑c ASCII chu·∫©n ƒë·ªÉ an to√†n nh·∫•t.
    window_name = "Dieu Chinh Mong Mat (Iris Tuner)" 
    cv2.namedWindow(window_name)
    
    # 1. Thanh tr∆∞·ª£t ƒë·ªô nh·∫°y: M·∫∑c ƒë·ªãnh 35%
    cv2.createTrackbar("Do Nhay %", window_name, 35, 100, nothing)
    # 2. Thanh tr∆∞·ª£t l√†m m·ªãn: M·∫∑c ƒë·ªãnh 5
    cv2.createTrackbar("Lam Min", window_name, 5, 20, nothing)
    
    print("\nüü¢ DANG CHAY... Chinh thanh truot de toi uu ket qua!")
    print("üëâ Bam 'q' de thoat chuong trinh.")

    prev_time = 0
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        # L·∫≠t ·∫£nh g∆∞∆°ng cho t·ª± nhi√™n
        frame = cv2.flip(frame, 1)
        original_h, original_w = frame.shape[:2]

        # 1. L·∫•y x√°c su·∫•t th√¥ (K√≠ch th∆∞·ªõc nh·ªè 320x320) -> T·ªêI ∆ØU H√ìA
        prob_map_small = segmentor.predict_raw_probs(frame)

        # 2. L·∫•y gi√° tr·ªã t·ª´ thanh tr∆∞·ª£t
        thresh_val = cv2.getTrackbarPos("Do Nhay %", window_name) / 100.0
        kernel_size = cv2.getTrackbarPos("Lam Min", window_name)
        if kernel_size < 1: kernel_size = 1

        # 3. X·ª≠ l√Ω tr√™n ·∫£nh nh·ªè (Nhanh h∆°n 4 l·∫ßn so v·ªõi x·ª≠ l√Ω ·∫£nh to)
        # T·∫°o mask th√¥
        mask_small = (prob_map_small > thresh_val).astype(np.uint8)

        # L·ªçc nhi·ªÖu (Morphology)
        kernel = np.ones((kernel_size, kernel_size), np.uint8)
        mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_OPEN, kernel)  # X√≥a nhi·ªÖu h·∫°t
        mask_small = cv2.morphologyEx(mask_small, cv2.MORPH_CLOSE, kernel) # L·∫•p l·ªó h·ªïng

        # 4. Ch·ªâ gi·ªØ v√πng l·ªõn nh·∫•t (Lo·∫°i b·ªè r√°c)
        cnts, _ = cv2.findContours(mask_small, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        clean_mask_small = np.zeros_like(mask_small)
        
        has_iris = False
        if cnts:
            largest_cnt = max(cnts, key=cv2.contourArea)
            # Ch·ªâ v·∫Ω n·∫øu v√πng ƒë·ªß l·ªõn (> 30 pixel ·ªü ƒë·ªô ph√¢n gi·∫£i th·∫•p)
            if cv2.contourArea(largest_cnt) > 30:
                cv2.drawContours(clean_mask_small, [largest_cnt], -1, 1, -1)
                has_iris = True
        
        # 5. Ph√≥ng to Mask l√™n k√≠ch th∆∞·ªõc Webcam (Resize 1 l·∫ßn duy nh·∫•t ·ªü ƒë√¢y)
        # D√πng INTER_NEAREST (Nhanh nh·∫•t) ho·∫∑c INTER_LINEAR (M∆∞·ª£t h∆°n x√≠u)
        final_mask = cv2.resize(clean_mask_small, (original_w, original_h), interpolation=cv2.INTER_NEAREST)

        # 6. V·∫Ω l√™n ·∫£nh g·ªëc
        result = frame.copy()
        
        if has_iris:
            # T·∫°o l·ªõp ph·ªß m√†u xanh
            overlay = np.zeros_like(frame)
            overlay[final_mask == 1] = (0, 255, 0) # Xanh l√°
            
            # Blend v√†o ·∫£nh g·ªëc
            result = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
            
            # V·∫Ω vi·ªÅn bao quanh (T√¨m l·∫°i contour tr√™n mask l·ªõn ƒë·ªÉ v·∫Ω vi·ªÅn cho n√©t)
            final_cnts, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if final_cnts:
                largest_final_cnt = max(final_cnts, key=cv2.contourArea)
                cv2.drawContours(result, [largest_final_cnt], -1, (0, 255, 255), 2) # Vi·ªÅn v√†ng

        # T√≠nh v√† hi·ªÉn th·ªã FPS
        curr_time = time.time()
        fps = 1 / (curr_time - prev_time) if prev_time > 0 else 0
        prev_time = curr_time

        # Hi·ªÉn th·ªã th√¥ng s·ªë ti·∫øng Vi·ªát
        cv2.putText(result, f"Toc do: {int(fps)} FPS", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        cv2.putText(result, f"Nguong: {int(thresh_val*100)}%", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)

        cv2.imshow(window_name, result)
        
        # Hi·ªÉn th·ªã Heatmap ·ªü c·ª≠a s·ªï nh·ªè (Debug)
        heatmap = (prob_map_small * 255).astype(np.uint8)
        heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        cv2.imshow("Ban Do Nhiet (Heatmap)", cv2.resize(heatmap_color, (320, 240)))

        if cv2.waitKey(1) & 0xFF == ord('q'): break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()