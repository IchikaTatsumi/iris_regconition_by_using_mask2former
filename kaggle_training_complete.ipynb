{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42abfcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# üî¨ Mask2Former Iris Segmentation Training\\n\",\n",
    "        \"\\n\",\n",
    "        \"## üìã Setup Checklist\\n\",\n",
    "        \"- [ ] GPU enabled (P100 or T4)\\n\",\n",
    "        \"- [ ] Internet enabled\\n\",\n",
    "        \"- [ ] Dataset added: `iris-segmentation-ubiris-v2`\\n\",\n",
    "        \"- [ ] Code added: `iris-segmentation-code`\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Expected training time: 8-10 hours**\\n\",\n",
    "        \"\\n\",\n",
    "        \"---\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 1: Check GPU and Environment\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"print(\\\"üîç Checking environment...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check GPU\\n\",\n",
    "        \"import subprocess\\n\",\n",
    "        \"result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\\n\",\n",
    "        \"print(result.stdout)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check PyTorch\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"print(f\\\"\\\\n‚úÖ PyTorch: {torch.__version__}\\\")\\n\",\n",
    "        \"print(f\\\"‚úÖ CUDA available: {torch.cuda.is_available()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"if torch.cuda.is_available():\\n\",\n",
    "        \"    print(f\\\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\\\")\\n\",\n",
    "        \"    memory = torch.cuda.get_device_properties(0).total_memory / 1e9\\n\",\n",
    "        \"    print(f\\\"‚úÖ Memory: {memory:.1f} GB\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if memory >= 15:\\n\",\n",
    "        \"        print(f\\\"‚úÖ Can use batch_size = 8\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(f\\\"‚ö†Ô∏è  Reduce batch_size to 4\\\")\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"‚ùå GPU NOT AVAILABLE - Check Settings ‚Üí Accelerator ‚Üí GPU!\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 2: Install Required Packages\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"print(\\\"üì¶ Installing dependencies...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Install packages (quiet mode)\\n\",\n",
    "        \"!pip install -q transformers==4.57.3\\n\",\n",
    "        \"!pip install -q albumentations==2.0.8\\n\",\n",
    "        \"!pip install -q timm einops\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\n‚úÖ Checking installations...\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Verify installations\\n\",\n",
    "        \"import transformers\\n\",\n",
    "        \"import albumentations\\n\",\n",
    "        \"import timm\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"‚úÖ Transformers: {transformers.__version__}\\\")\\n\",\n",
    "        \"print(f\\\"‚úÖ Albumentations: {albumentations.__version__}\\\")\\n\",\n",
    "        \"print(f\\\"‚úÖ Timm: {timm.__version__}\\\")\\n\",\n",
    "        \"print(\\\"\\\\n‚úÖ All dependencies installed!\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 3: Verify Datasets\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"üìÇ Checking datasets...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# List all inputs\\n\",\n",
    "        \"print(\\\"üìã Available datasets:\\\")\\n\",\n",
    "        \"!ls -la /kaggle/input/\\n\",\n",
    "        \"\\n\",\n",
    "        \"# ‚ö†Ô∏è IMPORTANT: Update these names to match YOUR dataset names!\\n\",\n",
    "        \"DATASET_NAME = 'iris-segmentation-ubiris-v2'  # ‚Üê CHANGE THIS\\n\",\n",
    "        \"CODE_NAME = 'iris-segmentation-code'          # ‚Üê CHANGE THIS\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"\\\\n\\\" + \\\"=\\\"*70)\\n\",\n",
    "        \"print(f\\\"Using dataset: {DATASET_NAME}\\\")\\n\",\n",
    "        \"print(f\\\"Using code: {CODE_NAME}\\\")\\n\",\n",
    "        \"print(\\\"=\\\"*70)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check dataset\\n\",\n",
    "        \"dataset_path = Path(f'/kaggle/input/{DATASET_NAME}/dataset')\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"\\\\nüìä Dataset: {DATASET_NAME}\\\")\\n\",\n",
    "        \"print(f\\\"   Path: {dataset_path}\\\")\\n\",\n",
    "        \"print(f\\\"   Exists: {dataset_path.exists()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"if dataset_path.exists():\\n\",\n",
    "        \"    images_dir = dataset_path / 'images'\\n\",\n",
    "        \"    masks_dir = dataset_path / 'masks'\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if images_dir.exists():\\n\",\n",
    "        \"        images = list(images_dir.glob('*'))\\n\",\n",
    "        \"        print(f\\\"   ‚úÖ Images: {len(images)} files\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(f\\\"   ‚ùå Images dir not found at {images_dir}\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if masks_dir.exists():\\n\",\n",
    "        \"        masks = list(masks_dir.glob('*'))\\n\",\n",
    "        \"        print(f\\\"   ‚úÖ Masks: {len(masks)} files\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(f\\\"   ‚ùå Masks dir not found at {masks_dir}\\\")\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(f\\\"   ‚ùå Dataset not found!\\\")\\n\",\n",
    "        \"    print(f\\\"\\\\nüí° Update DATASET_NAME in this cell to match your dataset name\\\")\\n\",\n",
    "        \"    print(f\\\"   Available: {[d.name for d in Path('/kaggle/input/').iterdir()]}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check code\\n\",\n",
    "        \"code_path = Path(f'/kaggle/input/{CODE_NAME}')\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"\\\\nüì¶ Code: {CODE_NAME}\\\")\\n\",\n",
    "        \"print(f\\\"   Path: {code_path}\\\")\\n\",\n",
    "        \"print(f\\\"   Exists: {code_path.exists()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"if code_path.exists():\\n\",\n",
    "        \"    print(f\\\"   ‚úÖ Code files found\\\")\\n\",\n",
    "        \"    !ls -la /kaggle/input/{CODE_NAME}/\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(f\\\"   ‚ùå Code not found!\\\")\\n\",\n",
    "        \"    print(f\\\"\\\\nüí° Update CODE_NAME in this cell to match your code dataset name\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 4: Extract Code to Working Directory\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"import shutil\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"üì• Extracting code...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Use same CODE_NAME from Cell 3\\n\",\n",
    "        \"CODE_NAME = 'iris-segmentation-code'  # ‚Üê Make sure this matches Cell 3\\n\",\n",
    "        \"\\n\",\n",
    "        \"code_path = Path(f'/kaggle/input/{CODE_NAME}')\\n\",\n",
    "        \"dest_path = Path('/kaggle/working/code')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Remove if exists\\n\",\n",
    "        \"if dest_path.exists():\\n\",\n",
    "        \"    print(\\\"   Removing old code...\\\")\\n\",\n",
    "        \"    shutil.rmtree(dest_path)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check structure and copy\\n\",\n",
    "        \"if (code_path / 'kaggle_code').exists():\\n\",\n",
    "        \"    # Code uploaded in kaggle_code/ subfolder\\n\",\n",
    "        \"    print(\\\"   Copying from kaggle_code/ subfolder...\\\")\\n\",\n",
    "        \"    shutil.copytree(code_path / 'kaggle_code', dest_path)\\n\",\n",
    "        \"elif (code_path / 'src').exists():\\n\",\n",
    "        \"    # Code uploaded directly\\n\",\n",
    "        \"    print(\\\"   Copying from root...\\\")\\n\",\n",
    "        \"    shutil.copytree(code_path, dest_path)\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"   ‚ùå Unexpected structure. Files in code dataset:\\\")\\n\",\n",
    "        \"    !ls -la /kaggle/input/{CODE_NAME}/\\n\",\n",
    "        \"    raise Exception(\\\"Cannot find code structure. Check your code dataset.\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"‚úÖ Code extracted to: {dest_path}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Change to code directory\\n\",\n",
    "        \"os.chdir(dest_path)\\n\",\n",
    "        \"print(f\\\"‚úÖ Changed directory to: {os.getcwd()}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# List files\\n\",\n",
    "        \"print(\\\"\\\\nüìã Code structure:\\\")\\n\",\n",
    "        \"!ls -la\\n\",\n",
    "        \"print(\\\"\\\\nüìÇ Source files:\\\")\\n\",\n",
    "        \"!ls -la src/\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 5: Update Config with Correct Paths\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"import json\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"üîß Updating config...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Load config\\n\",\n",
    "        \"config_path = Path('configs/mask2former_config_kaggle.json')\\n\",\n",
    "        \"\\n\",\n",
    "        \"if not config_path.exists():\\n\",\n",
    "        \"    print(f\\\"‚ùå Config not found: {config_path}\\\")\\n\",\n",
    "        \"    print(\\\"Available files in configs/:\\\")\\n\",\n",
    "        \"    !ls -la configs/\\n\",\n",
    "        \"    raise Exception(\\\"Config file not found\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"with open(config_path, 'r') as f:\\n\",\n",
    "        \"    config = json.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# ‚ö†Ô∏è IMPORTANT: Update dataset name to match YOUR dataset\\n\",\n",
    "        \"DATASET_NAME = 'iris-segmentation-ubiris-v2'  # ‚Üê CHANGE THIS to match Cell 3\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Update dataset paths\\n\",\n",
    "        \"config['data']['dataset_dir'] = f'/kaggle/input/{DATASET_NAME}/dataset'\\n\",\n",
    "        \"config['data']['dataset_root'] = f'/kaggle/input/{DATASET_NAME}/dataset'\\n\",\n",
    "        \"config['data']['images_dir'] = f'/kaggle/input/{DATASET_NAME}/dataset/images'\\n\",\n",
    "        \"config['data']['masks_dir'] = f'/kaggle/input/{DATASET_NAME}/dataset/masks'\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Update output paths\\n\",\n",
    "        \"config['output_dir'] = '/kaggle/working/outputs/mask2former_iris'\\n\",\n",
    "        \"config['checkpointing']['save_dir'] = '/kaggle/working/outputs/mask2former_iris'\\n\",\n",
    "        \"config['visualization']['save_dir'] = '/kaggle/working/outputs/mask2former_iris/visualizations'\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Disable WandB unless you have API key\\n\",\n",
    "        \"config['logging']['use_wandb'] = False\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Save updated config\\n\",\n",
    "        \"with open(config_path, 'w') as f:\\n\",\n",
    "        \"    json.dump(config, f, indent=2)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"‚úÖ Config updated!\\\")\\n\",\n",
    "        \"print(f\\\"\\\\nüìã Key settings:\\\")\\n\",\n",
    "        \"print(f\\\"   Dataset: {config['data']['dataset_root']}\\\")\\n\",\n",
    "        \"print(f\\\"   Batch size: {config['data']['batch_size']}\\\")\\n\",\n",
    "        \"print(f\\\"   Epochs: {config['training']['num_epochs']}\\\")\\n\",\n",
    "        \"print(f\\\"   Output: {config['output_dir']}\\\")\\n\",\n",
    "        \"print(f\\\"   Mixed precision: {config['training']['mixed_precision']}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Verify dataset exists\\n\",\n",
    "        \"dataset_path = Path(config['data']['dataset_root'])\\n\",\n",
    "        \"if dataset_path.exists():\\n\",\n",
    "        \"    images = list((dataset_path / 'images').glob('*'))\\n\",\n",
    "        \"    masks = list((dataset_path / 'masks').glob('*'))\\n\",\n",
    "        \"    print(f\\\"\\\\n‚úÖ Dataset verified: {len(images)} images, {len(masks)} masks\\\")\\n\",\n",
    "        \"    print(f\\\"\\\\nüéØ Ready to train!\\\")\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(f\\\"\\\\n‚ùå Dataset not found at: {dataset_path}\\\")\\n\",\n",
    "        \"    print(f\\\"\\\\nüí° Update DATASET_NAME in this cell to match your dataset!\\\")\\n\",\n",
    "        \"    print(f\\\"   Available datasets:\\\")\\n\",\n",
    "        \"    for d in Path('/kaggle/input/').iterdir():\\n\",\n",
    "        \"        print(f\\\"   ‚Ä¢ {d.name}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 6: Calculate Class Weights (Optional)\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"print(\\\"‚öñÔ∏è Calculating class weights...\\\")\\n\",\n",
    "        \"print(\\\"This may take 5-10 minutes...\\\\n\\\")\\n\",\n",
    "        \"print(\\\"üí° You can skip this if class_weights are already in config\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Run class weights utility\\n\",\n",
    "        \"!python class_weights_util.py\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\n‚úÖ Class weights calculated!\\\")\\n\",\n",
    "        \"print(\\\"Weights saved to: class_weights.pt\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 7: START TRAINING üöÄ\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"print(\\\"=\\\" * 70)\\n\",\n",
    "        \"print(\\\"üöÄ STARTING MASK2FORMER TRAINING\\\")\\n\",\n",
    "        \"print(\\\"=\\\" * 70)\\n\",\n",
    "        \"print(\\\"\\\\nüìä Expected timeline:\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Initialization: 5-10 minutes\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Per epoch: ~6-8 minutes (P100/T4)\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Total: 8-10 hours for 100 epochs\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Checkpoints saved every 20 epochs\\\")\\n\",\n",
    "        \"print(\\\"\\\\nüéØ Target metrics:\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Val mIoU: ‚â• 0.90\\\")\\n\",\n",
    "        \"print(\\\"   ‚Ä¢ Val Dice: ‚â• 0.93\\\")\\n\",\n",
    "        \"print(\\\"\\\\n‚ö†Ô∏è  Keep this tab open! Training will stop if you close it.\\\")\\n\",\n",
    "        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 70 + \\\"\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Start training\\n\",\n",
    "        \"!python train_mask2former.py --config configs/mask2former_config_kaggle.json\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n\",\n",
    "        \"print(\\\"‚úÖ TRAINING COMPLETED!\\\")\\n\",\n",
    "        \"print(\\\"=\\\" * 70)\\n\",\n",
    "        \"print(\\\"\\\\nüìä Check Cell 8 for results\\\")\\n\",\n",
    "        \"print(\\\"üíæ Run Cell 9 to download checkpoint\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 8: Check Training Results\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"üìä Checking training results...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"checkpoint_dir = Path('/kaggle/working/outputs/mask2former_iris/checkpoints')\\n\",\n",
    "        \"\\n\",\n",
    "        \"if not checkpoint_dir.exists():\\n\",\n",
    "        \"    print(\\\"‚ùå No checkpoints found. Training may have failed.\\\")\\n\",\n",
    "        \"    print(\\\"   Check training logs in Cell 7\\\")\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    checkpoints = list(checkpoint_dir.glob('*.pt'))\\n\",\n",
    "        \"    print(f\\\"‚úÖ Found {len(checkpoints)} checkpoints\\\\n\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # List all checkpoints\\n\",\n",
    "        \"    print(\\\"üìã Available checkpoints:\\\")\\n\",\n",
    "        \"    for ckpt in sorted(checkpoints):\\n\",\n",
    "        \"        size_mb = ckpt.stat().st_size / (1024 * 1024)\\n\",\n",
    "        \"        print(f\\\"   ‚Ä¢ {ckpt.name} ({size_mb:.1f} MB)\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Check best checkpoint\\n\",\n",
    "        \"    best_ckpt = checkpoint_dir / 'best.pt'\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if best_ckpt.exists():\\n\",\n",
    "        \"        print(f\\\"\\\\n\\\" + \\\"=\\\"*70)\\n\",\n",
    "        \"        print(f\\\"üèÜ BEST CHECKPOINT FOUND\\\")\\n\",\n",
    "        \"        print(\\\"=\\\"*70)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Load and show metrics\\n\",\n",
    "        \"        ckpt = torch.load(best_ckpt, map_location='cpu', weights_only=False)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        print(f\\\"\\\\nüìà Final Results:\\\")\\n\",\n",
    "        \"        print(f\\\"   Epoch: {ckpt.get('epoch', 'N/A')}\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        metrics = ckpt.get('metrics', {})\\n\",\n",
    "        \"        mean_iou = metrics.get('mean_iou', 0)\\n\",\n",
    "        \"        mean_dice = metrics.get('mean_dice', 0)\\n\",\n",
    "        \"        iris_iou = metrics.get('class_1_iou', 0)\\n\",\n",
    "        \"        iris_dice = metrics.get('class_1_dice', 0)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        print(f\\\"\\\\nüéØ Key Metrics:\\\")\\n\",\n",
    "        \"        print(f\\\"   Val mIoU:    {mean_iou:.4f} {'‚úÖ' if mean_iou >= 0.90 else '‚ö†Ô∏è'}  (target ‚â• 0.90)\\\")\\n\",\n",
    "        \"        print(f\\\"   Val Dice:    {mean_dice:.4f} {'‚úÖ' if mean_dice >= 0.93 else '‚ö†Ô∏è'}  (target ‚â• 0.93)\\\")\\n\",\n",
    "        \"        print(f\\\"   Iris IoU:    {iris_iou:.4f}\\\")\\n\",\n",
    "        \"        print(f\\\"   Iris Dice:   {iris_dice:.4f}\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        if 'boundary_f1' in metrics:\\n\",\n",
    "        \"            print(f\\\"   Boundary F1: {metrics['boundary_f1']:.4f}\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Overall assessment\\n\",\n",
    "        \"        print(f\\\"\\\\nüìä Overall Assessment:\\\")\\n\",\n",
    "        \"        if mean_iou >= 0.90 and mean_dice >= 0.93:\\n\",\n",
    "        \"            print(\\\"   ‚úÖ EXCELLENT - Both targets achieved!\\\")\\n\",\n",
    "        \"        elif mean_iou >= 0.85 and mean_dice >= 0.90:\\n\",\n",
    "        \"            print(\\\"   üü° GOOD - Close to targets\\\")\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            print(\\\"   ‚ö†Ô∏è  NEEDS IMPROVEMENT - Consider training longer\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # File info\\n\",\n",
    "        \"        size_mb = best_ckpt.stat().st_size / (1024 * 1024)\\n\",\n",
    "        \"        print(f\\\"\\\\nüíæ Checkpoint:\\\")\\n\",\n",
    "        \"        print(f\\\"   File: {best_ckpt.name}\\\")\\n\",\n",
    "        \"        print(f\\\"   Size: {size_mb:.1f} MB\\\")\\n\",\n",
    "        \"        print(f\\\"   Path: {best_ckpt}\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        print(f\\\"\\\\n\\\" + \\\"=\\\"*70)\\n\",\n",
    "        \"        print(\\\"‚úÖ Ready to download! Run Cell 9\\\")\\n\",\n",
    "        \"        print(\\\"=\\\"*70)\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(\\\"\\\\n‚ö†Ô∏è  best.pt not found\\\")\\n\",\n",
    "        \"        print(\\\"   Training may not have completed\\\")\\n\",\n",
    "        \"        print(\\\"   Or check for latest checkpoint above\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ============================================\\n\",\n",
    "        \"# CELL 9: Download Checkpoint ‚¨áÔ∏è\\n\",\n",
    "        \"# ============================================\\n\",\n",
    "        \"from IPython.display import FileLink\\n\",\n",
    "        \"import shutil\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"üì¶ Preparing downloads...\\\\n\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Best checkpoint\\n\",\n",
    "        \"best_ckpt = Path('/kaggle/working/outputs/mask2former_iris/checkpoints/best.pt')\\n\",\n",
    "        \"\\n\",\n",
    "        \"if best_ckpt.exists():\\n\",\n",
    "        \"    size_mb = best_ckpt.stat().st_size / (1024 * 1024)\\n\",\n",
    "        \"    print(f\\\"‚úÖ Best checkpoint ready!\\\")\\n\",\n",
    "        \"    print(f\\\"   Size: {size_mb:.1f} MB\\\")\\n\",\n",
    "        \"    print(f\\\"   File: {best_ckpt.name}\\\")\\n\",\n",
    "        \"    print(\\\"\\\\n‚¨áÔ∏è  Click link below to download best.pt:\\\")\\n\",\n",
    "        \"    display(FileLink(str(best_ckpt)))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Also prepare compressed version of all outputs\\n\",\n",
    "        \"    print(\\\"\\\\nüì¶ Compressing all results (checkpoints + visualizations)...\\\")\\n\",\n",
    "        \"    output_zip = '/kaggle/working/mask2former_results'\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    try:\\n\",\n",
    "        \"        shutil.make_archive(output_zip, 'zip', '/kaggle/working/outputs')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        zip_path = Path(output_zip + '.zip')\\n\",\n",
    "        \"        if zip_path.exists():\\n\",\n",
    "        \"            zip_size = zip_path.stat().st_size / (1024 * 1024)\\n\",\n",
    "        \"            print(f\\\"‚úÖ All results compressed: {zip_size:.1f} MB\\\")\\n\",\n",
    "        \"            print(\\\"\\\\n‚¨áÔ∏è  Click link below to download full results:\\\")\\n\",\n",
    "        \"            display(FileLink(str(zip_path)))\\n\",\n",
    "        \"        \\n\",\n",
    "        \"    except Exception as e:\\n\",\n",
    "        \"        print(f\\\"‚ö†Ô∏è  Could not create zip: {e}\\\")\\n\",\n",
    "        \"        print(\\\"   Download best.pt above instead\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    print(\\\"\\\\n\\\" + \\\"=\\\"*70)\\n\",\n",
    "        \"    print(\\\"üí° IMPORTANT: Download files before closing notebook!\\\")\\n\",\n",
    "        \"    print(\\\"=\\\"*70)\\n\",\n",
    "        \"    print(\\\"\\\\nüìã What to download:\\\")\\n\",\n",
    "        \"    print(\\\"   1. best.pt - Main checkpoint (for inference)\\\")\\n\",\n",
    "        \"    print(\\\"   2. mask2former_results.zip - Full results (optional)\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    print(\\\"\\\\nüéØ Next steps:\\\")\\n\",\n",
    "        \"    print(\\\"   1. Download best.pt\\\")\\n\",\n",
    "        \"    print(\\\"   2. Copy to local project: outputs/mask2former_iris/checkpoints/\\\")\\n\",\n",
    "        \"    print(\\\"   3. Run inference: python infer_mask2former.py --checkpoint best.pt\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"‚ùå Checkpoint not found at:\\\", best_ckpt)\\n\",\n",
    "        \"    print(\\\"\\\\nüí° Check if training completed successfully in Cell 7\\\")\\n\",\n",
    "        \"    print(\\\"   Or look for other checkpoints in Cell 8\\\")\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Try to find any checkpoint\\n\",\n",
    "        \"    checkpoint_dir = Path('/kaggle/working/outputs/mask2former_iris/checkpoints')\\n\",\n",
    "        \"    if checkpoint_dir.exists():\\n\",\n",
    "        \"        checkpoints = list(checkpoint_dir.glob('*.pt'))\\n\",\n",
    "        \"        if checkpoints:\\n\",\n",
    "        \"            print(\\\"\\\\nüìã Found these checkpoints instead:\\\")\\n\",\n",
    "        \"            for ckpt in checkpoints:\\n\",\n",
    "        \"                print(f\\\"   ‚Ä¢ {ckpt.name}\\\")\\n\",\n",
    "        \"                display(FileLink(str(ckpt)))\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"---\\n\",\n",
    "        \"\\n\",\n",
    "        \"## üéâ Training Complete!\\n\",\n",
    "        \"\\n\",\n",
    "        \"### What to do next:\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. ‚úÖ Download `best.pt` from Cell 9\\n\",\n",
    "        \"2. ‚úÖ Copy to local: `outputs/mask2former_iris/checkpoints/best.pt`\\n\",\n",
    "        \"3. ‚úÖ Run inference locally:\\n\",\n",
    "        \"   ```bash\\n\",\n",
    "        \"   python infer_mask2former.py \\\\\\n\",\n",
    "        \"       --checkpoint outputs/mask2former_iris/checkpoints/best.pt \\\\\\n\",\n",
    "        \"       --image dataset/images/C100_S1_I1.tiff \\\\\\n\",\n",
    "        \"       --output results/\\n\",\n",
    "        \"   ```\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Troubleshooting:\\n\",\n",
    "        \"\\n\",\n",
    "        \"- **No checkpoint?** ‚Üí Check Cell 7 logs for errors\\n\",\n",
    "        \"- **Low metrics?** ‚Üí Train longer or adjust hyperparameters\\n\",\n",
    "        \"- **Out of memory?** ‚Üí Reduce batch_size in Cell 5\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Resources:\\n\",\n",
    "        \"\\n\",\n",
    "        \"- [Mask2Former Paper](https://arxiv.org/abs/2112.01527)\\n\",\n",
    "        \"- [UBIRIS Dataset](http://iris.di.ubi.pt/ubiris2.html)\\n\",\n",
    "        \"- [Transformers Docs](https://huggingface.co/docs/transformers)\\n\",\n",
    "        \"\\n\",\n",
    "        \"---\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Good luck with your iris segmentation project! üöÄ**\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.10.0\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
